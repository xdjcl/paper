@article{kajan2006application,
  title={Application of a simple likelihood ratio approximant to protein sequence classification},
  author={Kaj{\'a}n, L{\'a}szl{\'o} and Kert{\'e}sz-Farkas, Attila and Franklin, Dino and Ivanova, Neli and Kocsor, Andr{\'a}s and Pongor, S{\'a}ndor},
  journal={Bioinformatics},
  volume={22},
  number={23},
  pages={2865--2869},
  year={2006},
  publisher={Oxford Univ Press}
}

@book{Wu2008,
abstract = {This paper presents the top 10 data mining algorithms identified by the IEEE International Conference on Data Mining (ICDM) in December 2006: C4.5, k-Means, SVM, Apriori, EM, PageRank, AdaBoost, k NN, Naive Bayes, and CART. These top 10 algorithms are among the most influential data mining algorithms in the research community. With each algorithm, we provide a description of the algorithm, discuss the impact of the algorithm, and review current and further research on the algorithm. These 10 algorithms cover classification, clustering, statistical learning, association analysis, and link mining, which are all among the most important topics in data mining research and development. {\textcopyright} Springer-Verlag London Limited 2007. },
author = {Wu, Xindong and Kumar, Vipin and Ross, Quinlan J. and Ghosh, Joydeep and Yang, Qiang and Motoda, Hiroshi and McLachlan, Geoffrey J. and Ng, Angus and Liu, Bing and Yu, Philip S. and Zhou, Zhi Hua and Steinbach, Michael and Hand, David J. and Steinberg, Dan},
booktitle = {Knowledge and Information Systems},
doi = {10.1007/s10115-007-0114-2},
file = {:C$\backslash$:/Users/xdjcl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2008 - Top 10 algorithms in data mining.pdf:pdf},
isbn = {1011500701},
issn = {02191377},
mendeley-groups = {学习/summary},
number = {1},
pages = {1--37},
title = {{Top 10 algorithms in data mining}},
volume = {14},
year = {2008}
}

@article{Xing2010,
abstract = {Sequence classification has a broad range of applications such as genomic analysis, information retrieval, health informatics, finance, and abnormal detection. Different from the classification task on feature vectors, sequences do not have explicit features. Even with sophisticated feature selection techniques, the dimensionality of potential features may still be very high and the sequential nature of features is difficult to capture. This makes sequence classification a more challenging task than classification on feature vectors. In this paper, we present a brief review of the existing work on sequence classification. We summarize the sequence classification in terms of methodologies and application domains. We also provide a review on several extensions of the sequence classification problem, such as early classification on sequences and semi-supervised learning on sequences.},
author = {Xing, Zhengzheng and Pei, Jian and Keogh, Eamonn},
doi = {10.1145/1882471.1882478},
file = {:E$\backslash$:/毕业设计/2009.pdf:pdf},
isbn = {1931-0145},
issn = {19310145},
journal = {ACM SIGKDD Explorations Newsletter},
mendeley-groups = {毕业设计},
month = {nov},
number = {1},
pages = {40},
title = {{A brief survey on sequence classification}},
url = {http://portal.acm.org/citation.cfm?doid=1882471.1882478},
volume = {12},
year = {2010}
}
@article{Ye2009,
abstract = {Classification of time series has been attracting great interest over the past decade. Recent empirical evidence has strongly suggested that the simple nearest neighbor algorithm is very difficult to beat for most time series problems. While this may be considered good news, given the simplicity of implementing the nearest neighbor algorithm, there are some negative consequences of this. First, the nearest neighbor algorithm requires storing and searching the entire dataset, resulting in a time and space complexity that limits its applicability, especially on resource-limited sensors. Second, beyond mere classification accuracy, we often wish to gain some insight into the data. In this work we introduce a new time series primitive, time series shapelets, which addresses these limitations. Informally, shapelets are time series subsequences which are in some sense maximally representative of a class. As we shall show with extensive empirical evaluations in diverse domains, algorithms based on the time series shapelet primitives can be interpretable, more accurate and significantly faster than state-of-the-art classifiers.},
author = {Ye, Lexiang and Keogh, Eamonn},
doi = {10.1145/1557019.1557122},
file = {:C$\backslash$:/Users/xdjcl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ye, Keogh - 2009 - Time series shapelets a new primitive for data mining.pdf:pdf},
isbn = {978-1-60558-495-9},
journal = {Proceedings of the ACM International Conference on Knowledge Discovery and Data Mining},
keywords = {classification,pattern extraction},
mendeley-groups = {毕业设计},
pages = {947--956},
title = {{Time series shapelets: a new primitive for data mining}},
url = {http://doi.acm.org/10.1145/1557019.1557122},
year = {2009}
}

@article{Al-Naymat2009,
abstract = {We present a new space-efficient approach, (SparseDTW), to compute the Dynamic Time Warping (DTW) distance between two time series that always yields the optimal result. This is in contrast to other known approaches which typically sacrifice optimality to attain space efficiency. The main idea behind our approach is to dynamically exploit the existence of similarity and/or correlation between the time series. The more the similarity between the time series the less space required to compute the DTW between them. To the best of our knowledge, all other techniques to speedup DTW, impose apriori constraints and do not exploit similarity characteristics that may be present in the data. We conduct experiments and demonstrate that SparseDTW outperforms previous approaches.},
archivePrefix = {arXiv},
arxivId = {1201.2969},
author = {Al-Naymat, Ghazi and Chawla, Sanjay and Taheri, Javid},
doi = {10.1007/s10115-004-0154-9},
eprint = {1201.2969},
file = {:E$\backslash$:/毕业设计/KAIS{\_}2004{\_}warping.pdf:pdf},
isbn = {9781920682828},
issn = {14451336},
journal = {Conferences in Research and Practice in Information Technology Series},
keywords = {Data mining,Dynamic time warping,Similarity measures,Time series},
mendeley-groups = {毕业设计},
number = {December 2003},
pages = {117--127},
pmid = {15470472},
title = {{SparseDTW: A novel approach to speed up dynamic time warping}},
volume = {101},
year = {2009}
}

@article{Batista2011,
abstract = {The ubiquity of time series data across almost all human endeavors has produced a great interest in time series data mining in the last decade. While there is a plethora of classification algorithms that can be applied to time series, all of the current empirical evidence suggests that simple nearest neighbor classification is exceptionally difficult to beat. The choice of distance measure used by the nearest neighbor algorithm depends on the invariances required by the domain. For example, motion capture data typically requires invariance to warping. In this work we make a surprising claim. There is an invariance that the community has missed, complexity invariance. Intuitively, the problem is that in many domains the different classes may have different complexities, and pairs of complex objects, even those which subjectively may seem very similar to the human eye, tend to be further apart under current distance measures than pairs of simple objects. This fact introduces errors in nearest neighbor classification, where complex objects are incorrectly assigned to a simpler class. We introduce the first complexity-invariant distance measure for time series, and show that it generally produces significant improvements in classification accuracy. We further show that this improvement does not compromise efficiency, since we can lower bound the measure and use a modification of triangular inequality, thus making use of most existing indexing and data mining algorithms. We evaluate our ideas with the largest and most comprehensive set of time series classification experiments ever attempted, and show that complexity-invariant distance measures can produce improvements in accuracy in the vast majority of cases. Copyright {\textcopyright} SIAM.},
author = {Batista, Gustavo E. a. P. a. and Wang, Xiaoyue and Keogh, Eamonn J},
doi = {http://dx.doi.org/10.1137/1.9781611972818.60},
file = {:E$\backslash$:/毕业设计/Complexity-Invariant Distance Measure.pdf:pdf},
isbn = {978-0-898719-92-5},
journal = {SIAM International Conference on Data Mining},
keywords = {classification,similarity measures,time series},
mendeley-groups = {毕业设计},
pages = {699--710},
pmid = {1000285860},
title = {{A Complexity-Invariant Distance Measure for Time Series}},
url = {http://epubs.siam.org/doi/abs/10.1137/1.9781611972818.60},
year = {2011}
}

@article{Ding2008,
abstract = {The last decade has witnessed a tremendous growths of interests in applications that deal with querying and mining of time series data. Numerous representation methods for dimensionality reduction and similarity measures geared towards time series have been introduced. Each individual work introducing a particular method has made specific claims and, aside from the occasional theoretical justifications, provided quantitative experimental observations. However, for the most part, the comparative aspects of these experiments were too narrowly focused on demonstrating the benefits of the proposed methods over some of the previously introduced ones. In order to provide a comprehensive validation, we conducted an extensive set of time series experiments re-implementing 8 different representation methods and 9 similarity measures and their variants, and testing their effectiveness on 38 time series data sets from a wide variety of application domains. In this paper, we give an overview of these different techniques and present our comparative experimental findings regarding their effectiveness. Our experiments have provided both a unified validation of some of the existing achievements, and in some cases, suggested that certain claims in the literature may be unduly optimistic. 1.},
archivePrefix = {arXiv},
arxivId = {1012.2789v1},
author = {Ding, H and Trajcevski, G and Scheuermann, P},
doi = {10.1145/1454159.1454226},
eprint = {1012.2789v1},
file = {:C$\backslash$:/Users/xdjcl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ding, Trajcevski, Scheuermann - 2008 - Querying and mining of time series data experimental comparison of representations and distance m.pdf:pdf},
isbn = {0000000000000},
issn = {2150-8097},
journal = {Proceedings of the VLDB Endowment},
mendeley-groups = {毕业设计},
number = {2},
pages = {1542--1552},
title = {{Querying and mining of time series data: experimental comparison of representations and distance measures}},
url = {http://dl.acm.org/citation.cfm?id=1454226},
volume = {1},
year = {2008}
}

@article{Keogh2000,
abstract = {There has been much recent interest in adapting data mining algorithms to time series databases. Most of these algorithms need to compare time series. Typically some variation of Euclidean distance is used. However, as we demonstrate in this paper, Euclidean distance can be an extremely brittle distance measure. Dynamic time warping (DTW) has been suggested as a technique to allow more robust distance calculations, however it is computationally expensive. In this paper we introduce a modification of DTW which operates on a higher level abstraction of the data, in particular, a Piecewise Aggregate Approximation (PAA). Our approach allows us to outperform DTW by one to two orders of magnitude, with no loss of accuracy.},
author = {Keogh, E. J and Pazzani, M. J},
doi = {10.1145/347090.347153},
file = {:E$\backslash$:/毕业设计/kdd{\_}2000.pdf:pdf},
isbn = {1581132336},
journal = {Knowledge discovery and data mining},
keywords = {dynamic time warping,similarity measures,time series},
mendeley-groups = {毕业设计},
pages = {285--289},
title = {{Scaling up dynamic time warping for datamining applications}},
url = {http://portal.acm.org/citation.cfm?doid=347090.347153$\backslash$nhttp://dl.acm.org/citation.cfm?id=347153},
volume = {In 6th ACM},
year = {2000}
}

@article{LESLIE2001,
author = {LESLIE, CHRISTINA and ESKIN, ELEAZAR and NOBLE, WILLIAM STAFFORD},
doi = {10.1142/9789812799623_0053},
file = {:C$\backslash$:/Users/xdjcl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/LESLIE, ESKIN, NOBLE - 2001 - the Spectrum Kernel a String Kernel for Svm Protein Classification.pdf:pdf},
isbn = {978-981-02-4777-5},
journal = {Biocomputing 2002},
mendeley-groups = {毕业设计},
pages = {564--575},
title = {{the Spectrum Kernel: a String Kernel for Svm Protein Classification}},
url = {http://www.worldscientific.com/doi/10.1142/9789812799623{\_}0053},
year = {2001}
}

@article{Lin2007,
abstract = {Many high level representations of time series have been proposed for data mining, including Fourier transforms, wavelets, eigenwaves, piecewise polynomial models, etc. Many researchers have also considered symbolic representations of time series, noting that such representations would potentiality allow researchers to avail of the wealth of data structures and algorithms from the text processing and bioinformatics communities. While many symbolic representations of time series have been introduced over the past decades, they all suffer from two fatal flaws. First, the dimensionality of the symbolic representation is the same as the original data, and virtually all data mining algorithms scale poorly with dimensionality. Second, although distance measures can be defined on the symbolic approaches, these distance measures have little correlation with distance measures defined on the original time series. In this work we formulate a new symbolic representation of time series. Our representation is unique in that it allows dimensionality/numerosity reduction, and it also allows distance measures to be defined on the symbolic approach that lower bound corresponding distance measures defined on the original series. As we shall demonstrate, this latter feature is particularly exciting because it allows one to run certain data mining algorithms on the efficiently manipulated symbolic representation, while producing identical results to the algorithms that operate on the original data. In particular, we will demonstrate the utility of our representation on various data mining tasks of clustering, classification, query by content, anomaly detection, motif discovery, and visualization.},
author = {Lin, Jessica and Keogh, Eamonn and Wei, Li and Lonardi, Stefano},
doi = {10.1007/s10618-007-0064-z},
file = {:C$\backslash$:/Users/xdjcl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin et al. - 2007 - Experiencing SAX A novel symbolic representation of time series.pdf:pdf},
isbn = {1384-5810},
issn = {13845810},
journal = {Data Mining and Knowledge Discovery},
keywords = {Data mining,Discretize,Symbolic representation,Time series},
mendeley-groups = {毕业设计},
number = {2},
pages = {107--144},
title = {{Experiencing SAX: A novel symbolic representation of time series}},
volume = {15},
year = {2007}
}

@article{Salvador2007,
abstract = {The dynamic time warping (DTW) algorithm is able to find the optimal alignment between two time series. It is often used to determine time series similarity, classification, and to find corresponding regions between two time series. DTW has a quadratic time and space complexity that limits its use to only small time series data sets. In this paper we introduce FastDTW, an approximation of DTW that has a linear time and space complexity. FastDTW uses a multilevel approach that recursively projects a solution from a coarse resolution and refines the projected solution. We prove the linear time and space complexity of FastDTW both theoretically and empirically. We also analyze the accuracy of FastDTW compared to two other existing approximate DTW algorithms: Sakoe-Chuba Bands and Data Abstraction. Our results show a large improvement in accuracy over the existing methods.},
author = {Salvador, Stan and Chan, Philip},
file = {:E$\backslash$:/毕业设计/Salvador2004.pdf:pdf},
issn = {1088467X},
journal = {Intelligent Data Analysis},
keywords = {dynamic time warping,time series},
mendeley-groups = {毕业设计},
pages = {561--580},
title = {{FastDTW : Toward Accurate Dynamic Time Warping in Linear Time and Space}},
url = {http://www.cs.fit.edu/{~}pkc/papers/tdm04.pdf},
volume = {11},
year = {2007}
}

@article{Thrun2000,
author = {Thrun, Sebastian and Mitchell, T O M and Nigam, Kamal},
file = {:E$\backslash$:/毕业设计/emcat-mlj99.pdf:pdf},
keywords = {bayesian learning,combining labeled and unlabeled,data,expectation-maximization,integrating supervised and unsupervised,learning,text classification},
mendeley-groups = {毕业设计},
pages = {103--134},
title = {{Text Classification from Labeled and Unlabeled Documents using EM}},
volume = {34},
year = {2000}
}@article{Salvador2007,
abstract = {The dynamic time warping (DTW) algorithm is able to find the optimal alignment between two time series. It is often used to determine time series similarity, classification, and to find corresponding regions between two time series. DTW has a quadratic time and space complexity that limits its use to only small time series data sets. In this paper we introduce FastDTW, an approximation of DTW that has a linear time and space complexity. FastDTW uses a multilevel approach that recursively projects a solution from a coarse resolution and refines the projected solution. We prove the linear time and space complexity of FastDTW both theoretically and empirically. We also analyze the accuracy of FastDTW compared to two other existing approximate DTW algorithms: Sakoe-Chuba Bands and Data Abstraction. Our results show a large improvement in accuracy over the existing methods.},
author = {Salvador, Stan and Chan, Philip},
file = {:E$\backslash$:/毕业设计/Salvador2004.pdf:pdf},
issn = {1088467X},
journal = {Intelligent Data Analysis},
keywords = {dynamic time warping,time series},
mendeley-groups = {毕业设计},
pages = {561--580},
title = {{FastDTW : Toward Accurate Dynamic Time Warping in Linear Time and Space}},
url = {http://www.cs.fit.edu/{~}pkc/papers/tdm04.pdf},
volume = {11},
year = {2007}
}


@article{Xi2006,
abstract = {Many algorithms have been proposed for the problem of time series classification. However, it is clear that one-nearest-neighbor with Dynamic Time Warping (DTW) distance is exceptionally difficult to beat. This approach has one weakness, however; it is computationally too demanding for many realtime applications. One way to mitigate this problem is to speed up the DTW calculations. Nonetheless, there is a limit to how much this can help. In this work, we propose an additional technique, numerosity reduction, to speed up one-nearest-neighbor DTW. While the idea of numerosity reduction for nearest-neighbor classifiers has a long history, we show here that we can leverage off an original observation about the relationship between dataset size and DTW constraints to produce an extremely compact dataset with little or no loss in accuracy. We test our ideas with a comprehensive set of experiments, and show that it can efficiently produce extremely fast accurate classifiers.},
author = {Xi, Xiaopeng and Keogh, Eamonn and Shelton, Christian and Wei, Li and Ratanamahatana, Chotirat Ann},
doi = {10.1145/1143844.1143974},
file = {:C$\backslash$:/Users/xdjcl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Xi et al. - 2006 - Fast time series classification using numerosity reduction(2).pdf:pdf},
isbn = {1595933832},
journal = {Proceedings of the 23rd international conference on Machine learning (ICML)},
mendeley-groups = {毕业设计},
pages = {1033----1040},
title = {{Fast time series classification using numerosity reduction}},
url = {http://dl.acm.org/citation.cfm?id=1143974},
year = {2006}
}

@article{Giorgino2009,
abstract = {Dynamic time warping is a popular technique for comparing time series, providing both a distance measure that is insensitive to local compression and stretches and the warping which optimally deforms one of the two input series onto the other. A variety of algorithms and constraints have been discussed in the literature. The dtw package provides an unification of them; it allows R users to compute time series alignments mixing freely a variety of continuity constraints, restriction windows, endpoints, local distance definitions, and so on. The package also provides functions for visualizing alignments and constraints using several classic diagram types.},
author = {Giorgino, Toni},
doi = {10.18637/jss.v031.i07},
file = {:E$\backslash$:/毕业设计/v31i07.pdf:pdf},
isbn = {1548-7660},
issn = {15487660},
journal = {Journal Of Statistical Software},
keywords = {alignment,dynamic programming,dynamic time warping,timeseries},
mendeley-groups = {毕业设计},
number = {7},
pages = {1--24},
title = {{Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package}},
url = {http://www.jstatsoft.org/v31/i07},
volume = {31},
year = {2009}
}

@misc{Shapelets_website,
   author = {Ye,L},
   title = {The Time Series Shapelets Webpage},
   howpublished = {\url{http://alumni.cs.ucr.edu/~lexiangy/shapelet.html}}
}

@misc{anthropology,
   author = {Eamonn Keogh},
   title = {UCR Computational Anthropology Site},
   howpublished = {\url{http://www.cs.ucr.edu/~eamonn/anthropology/}}
}

@misc{UCR_data,
   author = {Yanping Chen, Eamonn Keogh, Bing Hu.},
   title = {The UCR Time Series Classification Archive.},
   howpublished = {\url{http://www.cs.ucr.edu/~eamonn/time_series_data/}}
}

@article{Ratanamahatana2005,
abstract = {The Dynamic Time Warping (DTW) distance measure is a technique that has long been known in speech recognition community. It allows a non-linear mapping of one signal to another by minimizing the distance between the two. A decade ago, DTW was introduced into Data Mining community as a utility for various tasks for time series problems including classification, clustering, and anomaly detection. The technique has flourished, particularly in the last three years, and has been applied to a variety of problems in various disciplines. In spite of DTW's great success, there are still several persistent “myths” about it. These myths have caused confusion and led to much wasted research effort. In this work, we will dispel these myths with the most comprehensive set of time series experiments ever conducted.},
author = {Ratanamahatana, Chotirat Ann and Keogh, Eamonn},
doi = {http://dx.doi.org/10.1137/1.9781611972757.50},
file = {:E$\backslash$:/毕业设计/RatanamC.pdf:pdf},
isbn = {978-0-89871-593-4},
journal = {Proceedings of the 2005 SIAM International Conference on Data Mining},
keywords = {data mining,dynamic time warping,experimentation},
mendeley-groups = {毕业设计},
pages = {5},
title = {{Three Myths about Dynamic Time Warping Data Mining}},
year = {2005}
}
